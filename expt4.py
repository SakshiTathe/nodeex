# -*- coding: utf-8 -*-
"""Expt4.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1LVBTk-tMJoQ97WKILyCkJTLYacjNgdIx

MultiInput MultiOutput
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.datasets import fetch_california_housing
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
import tensorflow as tf
from tensorflow.keras import layers, Model, Input

"""Load Dataset"""

import pandas as pd
from sklearn.datasets import fetch_california_housing

housing = fetch_california_housing()
X = housing.data
y = housing.target

# Convert to DataFrame
df = pd.DataFrame(X, columns=housing.feature_names)
df['Target'] = y  # add target column

# Print first 5 rows
print(df.head())



"""(https://)Splitting into Inputs"""

X_main = X[:, :-2]       # Input 1 -> all features except lat, long
X_location = X[:, -2:]   # Input 2 -> latitude & longitude

"""Output 1: Regression target"""

X_main = X[:, :-2]       # Input 1 -> all features except lat, long
X_location = X[:, -2:]   # Input 2 -> latitude & longitude

"""# Output 2: Classification target (above/below median)"""

y_class = (y > np.median(y)).astype(int)

"""Train Test Split"""

X_main_train, X_main_test, X_loc_train, X_loc_test, y_reg_train, y_reg_test, y_class_train, y_class_test = train_test_split(
    X_main, X_location, y_reg, y_class, test_size=0.2, random_state=42
)

""" Scale inputs"""

scaler1 = StandardScaler()
X_main_train = scaler1.fit_transform(X_main_train)
X_main_test = scaler1.transform(X_main_test)

scaler2 = StandardScaler()
X_loc_train = scaler2.fit_transform(X_loc_train)
X_loc_test = scaler2.transform(X_loc_test)

"""Build MIMO Model"""

# Input 1: Main features
input_main = Input(shape=(X_main.shape[1],), name="Main_Features")
x1 = layers.Dense(64, activation="relu")(input_main)

# Input 2: Location features
input_loc = Input(shape=(2,), name="Location_Features")
x2 = layers.Dense(32, activation="relu")(input_loc)

# Merge both inputs
merged = layers.concatenate([x1, x2])
x = layers.Dense(64, activation="relu")(merged)

# Output 1: Regression (House Value)
output_reg = layers.Dense(1, name="HouseValue")(x)

# Output 2: Classification (High/Low Value)
output_class = layers.Dense(1, activation="sigmoid", name="HighValueClass")(x)

"""# Define model"""

model = Model(inputs=[input_main, input_loc], outputs=[output_reg, output_class])

"""Compile Model"""

model.compile(
    optimizer="adam",
    loss={"HouseValue": "mse", "HighValueClass": "binary_crossentropy"},
    metrics={"HouseValue": "mae", "HighValueClass": "accuracy"}
)

model.summary()

"""Train the Mode"""

history = model.fit(
    {"Main_Features": X_main_train, "Location_Features": X_loc_train},
    {"HouseValue": y_reg_train, "HighValueClass": y_class_train},
    validation_split=0.2,
    epochs=10,
    batch_size=32,
    verbose=1
)

"""Plot Training History"""

plt.figure(figsize=(12,5))

# Regression Loss
plt.subplot(1,2,1)
plt.plot(history.history["HouseValue_loss"], label="Train Regression Loss")
plt.plot(history.history["val_HouseValue_loss"], label="Val Regression Loss")
plt.legend()
plt.title("Regression Loss")

# Classification Accuracy
plt.subplot(1,2,2)
plt.plot(history.history["HighValueClass_accuracy"], label="Train Class Acc")
plt.plot(history.history["val_HighValueClass_accuracy"], label="Val Class Acc")
plt.legend()
plt.title("Classification Accuracy")

plt.show()