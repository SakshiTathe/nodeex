# -*- coding: utf-8 -*-
"""Expt_4_Neural_Network.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1IYrsJGDflds_1WgmW3Y8e89vYfNuBDtA
"""

import numpy as np
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from keras.models import Sequential
from keras.layers import Dense
from keras.utils import to_categorical
from tensorflow.keras import layers

from tensorflow import keras
from tensorflow.keras import layers

"""1. **Simple Sequential Model (Stack of Layers)**"""

model = keras.Sequential([
    layers.Dense(64, activation="relu"),
    layers.Dense(10, activation="softmax")
 ])

"""**Alternative way (same model, but adding layers one by one)**"""

model = keras.Sequential()
model.add(layers.Dense(64, activation="relu"))
model.add(layers.Dense(10, activation="softmax"))

model.build(input_shape=(None, 3))
model.weights

model.summary()

"""**ðŸ”¹ 2. Naming Models and Layers**"""

model = keras.Sequential(name="my_example_model")
model.add(layers.Dense(64, activation="relu", name="my_first_layer"))
model.add(layers.Dense(10, activation="softmax", name="my_last_layer"))
model.build((None, 3))
model.summary()

model = keras.Sequential()
model.add(keras.Input(shape=(3,)))
model.add(layers.Dense(64, activation="relu"))
model.summary()

model.add(layers.Dense(10, activation="softmax"))
model.summary()

"""**A simple Functional model with two Dense layers**"""

inputs = keras.Input(shape=(3,), name="my_input")
features = layers.Dense(64, activation="relu")(inputs)
outputs = layers.Dense(10, activation="softmax")(features)
model = keras.Model(inputs=inputs, outputs=outputs)

print(inputs.shape)

print(inputs.dtype)

print( features.shape)

model.summary()

"""**Multi-Input and Multi-Output Model**"""

vocabulary_size = 10000
num_tags = 100
num_departments = 4

#Inputs
title = keras.Input(shape=(vocabulary_size,), name="title")
text_body = keras.Input(shape=(vocabulary_size,), name="text_body")
tags = keras.Input(shape=(num_tags,), name="tags")

# combine features
features = layers.Concatenate()([title, text_body, tags])
features = layers.Dense(64, activation="relu")(features)
#Define  model outputs.
priority = layers.Dense(1, activation="sigmoid", name="priority")(features)
department = layers.Dense(num_departments, activation="softmax", name="department")(features)

#Build model
model = keras.Model(inputs=[title, text_body, tags], outputs=[priority, department])
model.summary()

import numpy as np

num_samples = 1280

title_data = np.random.randint(0, 2, size=(num_samples, vocabulary_size))
text_body_data = np.random.randint(0, 2, size=(num_samples, vocabulary_size))
tags_data = np.random.randint(0, 2, size=(num_samples, num_tags))
priority_data = np.random.random(size=(num_samples, 1))
department_data = np.random.randint(0, 2, size=(num_samples, num_departments))

#compiling
model.compile(optimizer="rmsprop",
              loss=["mean_squared_error", "categorical_crossentropy"],
              metrics=[["mean_absolute_error"], ["accuracy"]])
#training
model.fit([title_data, text_body_data, tags_data],
          [priority_data, department_data],
          epochs=1)
model.evaluate([title_data, text_body_data, tags_data],
               [priority_data, department_data])
priority_preds, department_preds = model.predict(
    [title_data, text_body_data, tags_data])

"""**Alternative: Dictionary Input/Output**"""

model.compile(optimizer="rmsprop",
              loss={"priority": "mean_squared_error", "department":
                    "categorical_crossentropy"},
              metrics={"priority": ["mean_absolute_error"], "department":
                       ["accuracy"]})
model.fit({"title": title_data, "text_body": text_body_data,
           "tags": tags_data},
          {"priority": priority_data, "department": department_data},
          epochs=1)
model.evaluate({"title": title_data, "text_body": text_body_data,
                "tags": tags_data},
               {"priority": priority_data, "department": department_data})
priority_preds, department_preds = model.predict(
    {"title": title_data, "text_body": text_body_data, "tags": tags_data})

"""**Visualizing the Model**"""

keras.utils.plot_model(model, "ticket_classifier.png")

keras.utils.plot_model(
    model, "ticket_classifier_with_shape_info.png", show_shapes=True)

import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers

(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()
x_train = x_train.reshape(-1, 784).astype("float32") / 255.0
x_test = x_test.reshape(-1, 784).astype("float32") / 255.0

inputs = keras.Input(shape=(784,))

x = layers.Dense(128, activation="relu")(inputs)
x = layers.Dropout(0.2)(x)
outputs = layers.Dense(10, activation="softmax")(x)

model = keras.Model(inputs=inputs, outputs=outputs)

model.compile(
    optimizer="adam",
    loss="sparse_categorical_crossentropy",
    metrics=["accuracy"]
)
history = model.fit(x_train, y_train, epochs=5, batch_size=64, validation_split=0.2)

test_loss, test_acc = model.evaluate(x_test, y_test, verbose=0)
print(f"Test Accuracy: {test_acc:.4f}")

"""**Movies Dataset**"""

import pandas as pd

ratings = pd.read_csv("ratings.dat", sep="::", engine='python', names=["user_id", "movie_id", "rating", "timestamp"])
users = pd.read_csv("users.dat", sep="::", engine='python', names=["user_id", "gender","age", "occupation", "zip_code"])
movies = pd.read_csv("movies.dat", sep="::", engine='python', encoding="latin-1",
                     names=["movie_id", "title", "genres"])

movies = pd.read_csv("movies.dat", sep="::", engine='python', names=["movie_id","title","genres"], encoding='latin-1')

genre_list = ["Action","Comedy","Drama","Romance","Thriller"]
for g in genre_list:
    movies[g] = movies['genres'].apply(lambda x: 1 if g in x else 0)

print(movies.columns)

genre_cols = ["Action","Comedy","Drama","Romance","Thriller"]

data = ratings.merge(users, on="user_id").merge(movies, on="movie_id")
data = data[["user_id", "age", "gender", "occupation", "movie_id", "rating"]+ genre_cols]

data.head(10)

from sklearn.preprocessing import LabelEncoder

data["gender"] = LabelEncoder().fit_transform(data["gender"].astype(str))
data["occupation"] = data["occupation"].astype(np.float32)
data["age"] = data["age"].astype(np.float32)

X_user = data[["age","gender","occupation"]].values.astype(np.float32)
movie_features = data[genre_cols].values.astype(np.float32)

y_rating = data["rating"].values.astype(np.float32).reshape(-1,1)
y_genre = movie_features.argmax(axis=1).astype(np.int32)

import numpy as np
from sklearn.model_selection import train_test_split

X_user_train, X_user_test, X_movie_train, X_movie_test, y_rating_train, y_rating_test, y_genre_train, y_genre_test = train_test_split(
    X_user, X_movie, y_rating, y_genre, test_size=0.2, random_state=42
)
#Before reshape: (50000,)   â†’ [4, 3, 5, 2, ...]
#After reshape : (50000,1) â†’ [[4], [3], [5], [2], ...]

y_rating_train = y_rating_train.reshape(-1, 1)
y_rating_test = y_rating_test.reshape(-1, 1)

col_mean = np.nanmean(X_user, axis=0)  # compute mean ignoring NaN
inds = np.where(np.isnan(X_user))
X_user[inds] = np.take(col_mean, inds[1])

import tensorflow as tf
from tensorflow.keras import layers, Model

user_input = layers.Input(shape=(3,), name="user_input")
movie_input = layers.Input(shape=(5,), name="movie_input")

u = layers.Dense(32, activation="relu")(user_input)
u = layers.Dense(16, activation="relu")(u)

m = layers.Dense(32, activation="relu")(movie_input)
m = layers.Dense(16, activation="relu")(m)

merged = layers.concatenate([u, m])
shared = layers.Dense(64, activation="relu")(merged)

rating_output = layers.Dense(1, name="rating_output")(shared)
genre_output = layers.Dense(5, activation="softmax", name="genre_output")(shared)

model = Model(inputs=[user_input, movie_input], outputs=[rating_output, genre_output])

model.compile(
    optimizer="adam",
    loss={
        "rating_output": "mse",
        "genre_output": "sparse_categorical_crossentropy"
    },
    metrics={
        "rating_output": "mae",
        "genre_output": "accuracy"
    }
)

model.summary()

from tensorflow.keras.utils import plot_model

plot_model(model, to_file='multi_modal_model.png', show_shapes=True, show_layer_names=True,dpi=50)

history = model.fit(
    {"user_input": X_user_train, "movie_input": X_movie_train},
    {"rating_output": y_rating_train, "genre_output": y_genre_train},
    validation_data=(
        {"user_input": X_user_test, "movie_input": X_movie_test},
        {"rating_output": y_rating_test, "genre_output": y_genre_test}
    ),
    epochs=5,
    batch_size=32
)

results = model.evaluate(
    {"user_input": X_user_test, "movie_input": X_movie_test},
    {"rating_output": y_rating_test, "genre_output": y_genre_test},
    batch_size=32
)
print("Test results:", results)

preds = model.predict(
    {"user_input": X_user_test, "movie_input": X_movie_test}
)

rating_preds = preds[0]  # shape (num_samples, 1)
genre_preds = preds[1]   # shape (num_samples, 5, softmax probabilities)

import numpy as np

genre_pred_labels = np.argmax(genre_preds, axis=1)  # 0 to 4



for i in range(5):
    print(f"True rating: {y_rating_test[i][0]}, Predicted rating: {rating_preds[i][0]:.2f}")

for i in range(5):
    print(f"True genre: {y_genre_test[i]}, Predicted genre: {genre_pred_labels[i]}")